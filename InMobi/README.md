# Interview Process for Big Data Engineer 2020 (Personal):  
1. First round of interview with onshore engineering manager from U.S.A.  
2. Questions about your work experience on distributed systems, spark and data engineering pipelines.  
3. what is it that you do as a part of your daily routine at work?  
4. Tell me your understanding about hadoop?  
5. What kind of challenges did you face in your projects? and How did you resolve them?  
6. How do you handle memory leaks/failure of jobs due to memory errors?  
7. Explain your understanding of hive internal table vs external table?  
8. How did you optimize complex queries in hive?  - partitions, buckets etc  
9. How do you handle spark applications that are taking too long (certain task is leading to memory leaks)?  
